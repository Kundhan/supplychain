{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11a90623-fb2d-48e6-beb0-e36fb00420a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Following cells illustrate the medallion architecture , its an architecture that suits Retail grocery store\n",
    "#task 1 # Supply config through a config file azure datalake store gen 2 to repeat the task for shipment details as well.\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Kafka details (HDInsight)\n",
    "KAFKA_BROKERS = \"kafka-broker1:9092,kafka-broker2:9092\"\n",
    "KAFKA_TOPIC = \"inventory_events\"\n",
    "KAFKA_SECURITY_PROTOCOL = \"SASL_SSL\"\n",
    "\n",
    "# Read streaming data from Kafka\n",
    "kafka_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", KAFKA_BROKERS) \\\n",
    "    .option(\"subscribe\", KAFKA_TOPIC) \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .option(\"kafka.security.protocol\", KAFKA_SECURITY_PROTOCOL) \\\n",
    "    .load()\n",
    "\n",
    "# Define schema for inventory data\n",
    "shipment_summary_schema = StructType([\n",
    "    StructField(\"product_id\", StringType(), True),\n",
    "    StructField(\"store_id\", StringType(), True),\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"purchase_order\", IntegerType(), True),\n",
    "    StructField(\"temperature\", DoubleType(), True),\n",
    "    StructField(\"supplier_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Parse JSON messages\n",
    "bronze_df = kafka_df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "    .select(from_json(col(\"value\"), shipment_summary_schema).alias(\"data\")) \\\n",
    "    .select(\"data.*\") \\\n",
    "    .withColumn(\"event_time\", to_timestamp(\"timestamp\"))\n",
    "\n",
    "# Write to Delta Table (Bronze Layer) in ADLS Gen2\n",
    "bronze_df.writeStream \\\n",
    "    .format(\"delta\") \\\n",
    "    .option(\"checkpointLocation\", \"abfss://bronze@storage.dfs.core.windows.net/checkpoints/\") \\\n",
    "    .option(\"path\", \"abfss://bronze@storage.dfs.core.windows.net/shipment_summary/\") \\\n",
    "    .partitionBy(\"store_id\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "bronze_data_ingestion_2025-02-16 17:46:15",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
